<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="Balagopal Komarath" />
  <title> </title>
  <link rel="stylesheet" type="text/css" href="/css/bk.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/bkprint.css" />
  
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  
</head>
<body>
  <header>
  <a class="logo" href="/">bkomarath</a>
  <a class="menu" href="/menu">Menu</a>
</header>

  
  <main>
    <h1>Asymptotic analysis</h1>
    <p>We would like to classify functions based on the <em>order</em> of their growth. Function \(f(n) = 3n^2\) and \(g(n) = 2n^2 + n + \log(n)\) are different but in a sense the same when you consider the order of their growth. More concretely, they both satisfy the equation \(\lim_{n \to \infty} h(2n)/h(n) = 4\). We can think of \(f\) and \(g\) as time taken by some algorithms. Then, the limit communicates the information that if we double the size of the input, the running time increases by a factor of four.</p>
<p>Running times are functions on natural numbers. We can only take limits of continuous functions on real numbers. So to do the above analysis, we need to develop a new theory to measure the order of growth of functions on natural numbers. This theory is called <em>asymptotic analysis of discrete functions</em>. The fundamental question answered by this theory is: Given functions \(f\) and \(g\), how is the order of growth of \(f\) related to the order of growth of \(g\)?</p>
<p>We use \(O(f)\) to denote the set of all functions that grow at most as fast as \(f\). We want to define \(O(.)\) so that we can make assertions like \(2n^2 + n + \log(n) \in O(n^3)\), which should be read as: &ldquo;The function \(g(n) = 2n^2 + n + \log(n)\) grows at most as fast as \(n^3\)&rdquo;. This is true because the value of \(g\) increases by four times when \(n\) doubles whereas the value of \(n^3\) increases by eight times when \(n\) doubles. So as \(n\) grows larger, the value of \(n^3\) will eventually be larger, and stay larger, than that of \(g(n)\). We also want to assert that \(1000n^3 \in O(n^3)\) because even though the value of \(n^3\) can never be larger than that of \(1000n^3\), the rate of growth of \(1000n^3\) is at most that of \(n^3\).</p>
<p>\begin{align*}
O(f) &amp;= \{ g \mid \exists [n_0, c &gt; 0](\forall [n \geq n_0](g(n) \leq cf(n)))\} \\
\Omega(f) &amp;= \{ g \mid \exists [n_0, c &gt; 0](\forall [n \geq n_0](g(n) \geq cf(n)))\} \\
\Theta(f) &amp;= O(f) \cap \Omega(f)
\end{align*}</p>
<h2 id="exercise">Exercise</h2>
<ol>
<li>The <em>Fibonacci sequence</em> is given by the recurrence: \(F_0=F_1=1\), \(F_n=F_{n-1} + F_{n-2}\) for \(n&gt;2\). What is the largest Fibonacci number that can fit into a word in a 64-bit machine? What about 128-bit machines?</li>
</ol>

    
    <nav class="chapter">
      <ul>
        
        <li><a href="https://bkomarath.rbgo.in/dsa/machines-and-computation/proofs/">→ Proofs</a></li>
        
        
        <li><a href="https://bkomarath.rbgo.in/dsa/machines-and-computation/time/">← Time</a></li>
        
        <li><a href="/dsa">↑ Data Structures and Algorithms</a></li>
      </ul>
    </nav>
  </main>

  <footer>
  <p>
    All content on this website is licensed under
    <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA
      4.0</a> by Balagopal Komarath unless mentioned otherwise.
</footer>

</body>
</html>
