<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="Balagopal Komarath" />
  <title>
Special Topics Course: Algebraic Complexity Theory (2021)
</title>
  <link rel="stylesheet" type="text/css" href="/css/bk.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/bkprint.css" />
  
</head>
<body>
  <header>
  <a class="logo" href="/">bkomarath</a>
  <a class="menu" href="/menu">Menu</a>
</header>

  
<main>
  <h1>Special Topics Course: Algebraic Complexity Theory (2021)</h1>
  <h2 id="welcome">Welcome</h2>
<p>Algebraic complexity theory deals with the computation of polynomials using the basic operations addition and multiplication. For example, we can compute the polynomial \(xy + xz\) using two multiplications and one addition. By using distributivity, we can perform the same computation as \(x(y + z)\) which costs one addition and only one multiplication. The primary goal of algebraic complexity theory is to understand the minimum number of operations for computing interesting polynomials such as determinants and matrix multiplication polynomials (also called the complexity of these polynomials). For example, can we prove that multiplying two n x n matrices can be done using \(n^2\) operations? (The trivial method uses \(n^3\) operations. We can improve it as much as \(n^2.{37}\))</p>
<p>In this course, we will first learn about polynomial families such as matrix multiplication polynomials, determinants, and permanents. What makes them interesting is the fact that they seem to characterize the complexity of large classes of interesting polynomials? For example, any polynomial that can be written as a small formula can also be written as a small determinant. We will then look at very clever ways to compute polynomials efficiently such as computing all first-order partial derivatives of an n-variate polynomial using almost the same number of operations as for the polynomial (If you compute them individually, you&rsquo;ll need about n times more, which is too much)! and the theory underlying Strassen&rsquo;s fast matrix multiplication algorithm.</p>
<p>Even though we have many clever algorithms to efficiently compute certain important polynomials, there seems to be a lack of techniques that will allow us to prove that certain polynomials are hard to compute, despite our strong suspicion that they actually are hard to compute. Nevertheless, we can impose natural restrictions such as monotonicity (disallow subtraction), constant-depth (limit nesting of operations), multilinearity (disallow squaring variables) and show that under these restrictions, certain polynomials are hard to compute.</p>
<h2 id="contact">Contact</h2>
<p>Please write to Balagopal Komarath &lt;<a href="mailto:bkomarath@iitgn.ac.in">bkomarath@iitgn.ac.in</a>&gt; for any course related queries.</p>
<h2 id="lectures">Lectures</h2>
<p>The lectures will be conducted on slots M1+N1, N3. Please use this <a href="https://meet.google.com/ivt-hgvz-dqa">link</a> to join.</p>
<h2 id="evaluation">Evaluation</h2>
<ul>
<li>Presentations (30%)</li>
<li>Take-home assignments (30%)</li>
<li>End-sem viva (40%)</li>
</ul>
<h2 id="references">References</h2>
<ol>
<li>Completeness and Reduction in Algebraic Complexity Theory, Peter Bürgisser.</li>
<li><a href="https://cims.nyu.edu/~regev/toc/articles/gs005/index.html">Fast Matrix Multiplication</a>, Markus Bläser.</li>
<li><a href="https://github.com/dasarpmar/lowerbounds-survey">Arithmetic circuits lower-bounds survey</a>, Ramprasad Saptarishi.</li>
</ol>

</main>

  <footer>
  <p>
    All content on this website is licensed under
    <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA
      4.0</a> by Balagopal Komarath unless mentioned otherwise.
</footer>

</body>
</html>
